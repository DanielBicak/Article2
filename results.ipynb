{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from libpysal.weights import lat2W\n",
    "from esda.moran import Moran\n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>relationship</th>\n",
       "      <th>coeficients</th>\n",
       "      <th>trend</th>\n",
       "      <th>surface_level</th>\n",
       "      <th>spatial_autocorrelation</th>\n",
       "      <th>dataset_path</th>\n",
       "      <th>target_path</th>\n",
       "      <th>trend_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>[[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....</td>\n",
       "      <td>none</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>dataset-TR_none_rel-linear-lvl_small-sac-high.csv</td>\n",
       "      <td>target-TR_none_rel-linear-lvl_small-sac-high.csv</td>\n",
       "      <td>trend_none.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>[[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....</td>\n",
       "      <td>none</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>dataset-TR_none_rel-linear-lvl_small-sac-low.csv</td>\n",
       "      <td>target-TR_none_rel-linear-lvl_small-sac-low.csv</td>\n",
       "      <td>trend_none.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>linear</td>\n",
       "      <td>[[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....</td>\n",
       "      <td>none</td>\n",
       "      <td>small</td>\n",
       "      <td>none</td>\n",
       "      <td>dataset-TR_none_rel-linear-lvl_small-sac-none.csv</td>\n",
       "      <td>target-TR_none_rel-linear-lvl_small-sac-none.csv</td>\n",
       "      <td>trend_none.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>polynom2</td>\n",
       "      <td>[[2, -1, 0.25], [-2, -1, -0.25], [-2, 1, -0.25...</td>\n",
       "      <td>none</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>dataset-TR_none_rel-polynom2-lvl_small-sac-hig...</td>\n",
       "      <td>target-TR_none_rel-polynom2-lvl_small-sac-high...</td>\n",
       "      <td>trend_none.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>polynom2</td>\n",
       "      <td>[[2, -1, 0.25], [-2, -1, -0.25], [-2, 1, -0.25...</td>\n",
       "      <td>none</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>dataset-TR_none_rel-polynom2-lvl_small-sac-low...</td>\n",
       "      <td>target-TR_none_rel-polynom2-lvl_small-sac-low.csv</td>\n",
       "      <td>trend_none.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id relationship                                        coeficients trend  \\\n",
       "0   0       linear  [[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....  none   \n",
       "1   1       linear  [[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....  none   \n",
       "2   2       linear  [[1.5, 0.25], [1.5, -0.25], [-1.5, 0.25], [-1....  none   \n",
       "3   3     polynom2  [[2, -1, 0.25], [-2, -1, -0.25], [-2, 1, -0.25...  none   \n",
       "4   4     polynom2  [[2, -1, 0.25], [-2, -1, -0.25], [-2, 1, -0.25...  none   \n",
       "\n",
       "  surface_level spatial_autocorrelation  \\\n",
       "0         small                    high   \n",
       "1         small                     low   \n",
       "2         small                    none   \n",
       "3         small                    high   \n",
       "4         small                     low   \n",
       "\n",
       "                                        dataset_path  \\\n",
       "0  dataset-TR_none_rel-linear-lvl_small-sac-high.csv   \n",
       "1   dataset-TR_none_rel-linear-lvl_small-sac-low.csv   \n",
       "2  dataset-TR_none_rel-linear-lvl_small-sac-none.csv   \n",
       "3  dataset-TR_none_rel-polynom2-lvl_small-sac-hig...   \n",
       "4  dataset-TR_none_rel-polynom2-lvl_small-sac-low...   \n",
       "\n",
       "                                         target_path      trend_path  \n",
       "0   target-TR_none_rel-linear-lvl_small-sac-high.csv  trend_none.csv  \n",
       "1    target-TR_none_rel-linear-lvl_small-sac-low.csv  trend_none.csv  \n",
       "2   target-TR_none_rel-linear-lvl_small-sac-none.csv  trend_none.csv  \n",
       "3  target-TR_none_rel-polynom2-lvl_small-sac-high...  trend_none.csv  \n",
       "4  target-TR_none_rel-polynom2-lvl_small-sac-low.csv  trend_none.csv  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data and compute rmse/mae\n",
    "# load metadata\n",
    "\n",
    "metadata = pd.read_csv('dataset_info.csv')\n",
    "metadata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7be73ba17584518b0fb685792ccf415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "spatial_autocorrelation_val = []\n",
    "\n",
    "m = 160\n",
    "\n",
    "# calculate value of spatial autocorrelation \n",
    "for row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "\n",
    "    # name of the file\n",
    "    name = row[1]['target_path']\n",
    "\n",
    "    # load values of dependent feature\n",
    "    label = np.genfromtxt(f\"data_labels\\\\{name}\", delimiter=',')\n",
    "\n",
    "    w = lat2W(m, m, rook=False, id_type=\"int\")\n",
    "    mi = Moran(label.reshape(m, m), w).I\n",
    "    spatial_autocorrelation_val.append(mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference_percent(old, new):\n",
    "    old_arr = np.array(old)\n",
    "    new_arr = np.array(new)\n",
    "    return list(((old_arr-new_arr)/old_arr)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR REGRESION\n",
    "lr_coord_rmse = []\n",
    "lr_no_coord_rmse = []\n",
    "glr_rmse = []\n",
    "msglr_rmse = []\n",
    "lr_bandwidth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a0caa85e1144f3bba4ff1c303d0ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "\n",
    "    id_dataset = row[1]['id']\n",
    "\n",
    "    # load dataset\n",
    "    features =  np.genfromtxt(f\"data_features\\\\{row[1]['dataset_path']}\", delimiter=',')\n",
    "    labels = np.genfromtxt(f\"data_labels\\\\{row[1]['target_path']}\", delimiter=',')\n",
    "\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    c_test = X_test[:, -2:]\n",
    "\n",
    "    limits_ind = [20,120,20,120]\n",
    "    limits_indx = np.where((c_test[:,0] > limits_ind[0]) & (c_test[:,0] < limits_ind[1])\n",
    "                            & (c_test[:,1] > limits_ind[2]) & (c_test[:,1] < limits_ind[3]))[0]\n",
    "    \n",
    "    y_test = y_test[limits_indx]\n",
    "\n",
    "    # LINEAR REGRESSION\n",
    "    # load prediction from coord LR\n",
    "    pred_lr_coord = np.genfromtxt(f\"testingLR\\\\LR_coord\\\\LR_coord_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from no coord LR\n",
    "    pred_lr_no_coord = np.genfromtxt(f\"testingLR\\\\LR\\\\LR_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from GLR\n",
    "    pred_glr = np.genfromtxt(f\"testingLR\\\\GLR\\\\GLR_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from MSGLR \n",
    "    pred_msglr = np.genfromtxt(f\"testingLR\\\\MSGLR\\\\MSGLR_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # calculate rmse\n",
    "    rmse_lr_coord = mean_squared_error(y_test, pred_lr_coord, squared=False)\n",
    "    rmse_lr_no_coord = mean_squared_error(y_test, pred_lr_no_coord, squared=False)\n",
    "    rmse_glr = mean_squared_error(y_test, pred_glr, squared=False)\n",
    "    rmse_msglr = mean_squared_error(y_test, pred_msglr, squared=False)\n",
    "\n",
    "    # get single bandwidth\n",
    "    bandwidth = np.genfromtxt(f\"tuningLR\\\\single_bandwidth\\\\single_bandwidth_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # append to list\n",
    "    lr_coord_rmse.append(rmse_lr_coord)\n",
    "    lr_no_coord_rmse.append(rmse_lr_no_coord)\n",
    "    glr_rmse.append(rmse_glr)\n",
    "    msglr_rmse.append(rmse_msglr)\n",
    "    lr_bandwidth.append(bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-53-b9ec4a9852f5>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataLR['algorithm'] = ['LinearRegression'] * len(result_dataLR)\n",
      "<ipython-input-53-b9ec4a9852f5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataLR['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
      "<ipython-input-53-b9ec4a9852f5>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataLR['bandwidth'] = lr_bandwidth\n",
      "<ipython-input-53-b9ec4a9852f5>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataLR['Coordinates'] = lr_coord_rmse\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_dataLR = metadata[['relationship','trend', 'surface_level', 'spatial_autocorrelation', ]]\n",
    "result_dataLR['algorithm'] = ['LinearRegression'] * len(result_dataLR)\n",
    "result_dataLR['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
    "result_dataLR['bandwidth'] = lr_bandwidth\n",
    "\n",
    "result_dataLR['Coordinates'] = lr_coord_rmse\n",
    "result_dataLR['No_coordinates'] = lr_no_coord_rmse\n",
    "result_dataLR['Add_coordinates_change'] = difference_percent(lr_no_coord_rmse, lr_coord_rmse)\n",
    "result_dataLR['Geographical'] = glr_rmse\n",
    "result_dataLR['Geographical_change'] = difference_percent(lr_no_coord_rmse, glr_rmse)\n",
    "result_dataLR['Multiscale'] = msglr_rmse\n",
    "result_dataLR['Multiscale_change'] = difference_percent(lr_no_coord_rmse, msglr_rmse)\n",
    "\n",
    "result_dataLR.to_csv(\"resultLR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_data = metadata[['relationship','trend', 'surface_level', 'spatial_autocorrelation', ]]\n",
    "len(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST\n",
    "rf_coord_rmse = []\n",
    "rf_no_coord_rmse = []\n",
    "grf_rmse = []\n",
    "msgrf_rmse = []\n",
    "\n",
    "rf_bandwidth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf31eb712a77447ea7d9c40a9f4dc6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "\n",
    "    id_dataset = row[1]['id']\n",
    "\n",
    "    # load dataset\n",
    "    features =  np.genfromtxt(f\"data_features\\\\{row[1]['dataset_path']}\", delimiter=',')\n",
    "    labels = np.genfromtxt(f\"data_labels\\\\{row[1]['target_path']}\", delimiter=',')\n",
    "\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    c_test = X_test[:, -2:]\n",
    "\n",
    "    limits_ind = [20,120,20,120]\n",
    "    limits_indx = np.where((c_test[:,0] > limits_ind[0]) & (c_test[:,0] < limits_ind[1])\n",
    "                            & (c_test[:,1] > limits_ind[2]) & (c_test[:,1] < limits_ind[3]))[0]\n",
    "    \n",
    "    y_test = y_test[limits_indx]\n",
    "\n",
    "    # RANDOM FOREST\n",
    "    # load prediction from coord RF\n",
    "    pred_rf_coord = np.genfromtxt(f\"testingRF\\\\RF_coord\\\\RF_coord_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from no coord RF\n",
    "    pred_rf_no_coord = np.genfromtxt(f\"testingRF\\\\RF\\\\RF_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from GRF\n",
    "    pred_grf = np.genfromtxt(f\"testingRF\\\\GRF\\\\GRF_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from MSGRF \n",
    "    pred_msgrf = np.genfromtxt(f\"testingRF\\\\MSGRF\\\\MSGRF_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # get single bandwidth\n",
    "    bandwidth = np.genfromtxt(f\"tuningRF\\\\single_bandwidth\\\\single_bandwidth_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # calculate rmse\n",
    "    rmse_rf_coord = mean_squared_error(y_test, pred_rf_coord, squared=False)\n",
    "    rmse_rf_no_coord = mean_squared_error(y_test, pred_rf_no_coord, squared=False)\n",
    "    rmse_grf = mean_squared_error(y_test, pred_grf, squared=False)\n",
    "    rmse_msgrf = mean_squared_error(y_test, pred_msgrf, squared=False)\n",
    "\n",
    "    rf_bandwidth.append(bandwidth)\n",
    "\n",
    "    # append to list\n",
    "    rf_coord_rmse.append(rmse_rf_coord)\n",
    "    rf_no_coord_rmse.append(rmse_rf_no_coord)\n",
    "    grf_rmse.append(rmse_grf)\n",
    "    msgrf_rmse.append(rmse_msgrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-46f7367ed8e5>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataRF['algorithm'] = ['RandomForest'] * len(result_data)\n",
      "<ipython-input-52-46f7367ed8e5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataRF['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
      "<ipython-input-52-46f7367ed8e5>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataRF['bandwidth'] = rf_bandwidth\n",
      "<ipython-input-52-46f7367ed8e5>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataRF['Coordinates'] = rf_coord_rmse\n"
     ]
    }
   ],
   "source": [
    "result_dataRF = metadata[['relationship','trend', 'surface_level', 'spatial_autocorrelation', ]]\n",
    "result_dataRF['algorithm'] = ['RandomForest'] * len(result_data)\n",
    "result_dataRF['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
    "result_dataRF['bandwidth'] = rf_bandwidth\n",
    "\n",
    "\n",
    "result_dataRF['Coordinates'] = rf_coord_rmse\n",
    "result_dataRF['No_coordinates'] = rf_no_coord_rmse\n",
    "result_dataRF['Add_coordinates_change'] = difference_percent(rf_no_coord_rmse, rf_coord_rmse)\n",
    "result_dataRF['Geographical'] = grf_rmse\n",
    "result_dataRF['Geographical_change'] = difference_percent(rf_no_coord_rmse, grf_rmse)\n",
    "result_dataRF['Multiscale'] = msgrf_rmse\n",
    "result_dataRF['Multiscale_change'] = difference_percent(rf_no_coord_rmse, msgrf_rmse)\n",
    "\n",
    "result_dataRF.to_csv(\"resultRF.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUPPORT VECTOR MACHINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svm_coord_rmse = []\n",
    "svm_no_coord_rmse = []\n",
    "gsvm_rmse = []\n",
    "msgsvm_rmse = []\n",
    "svm_bandwidth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50da012df1c34879b054128339391328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=135.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "\n",
    "    id_dataset = row[1]['id']\n",
    "\n",
    "    # load dataset\n",
    "    features =  np.genfromtxt(f\"data_features\\\\{row[1]['dataset_path']}\", delimiter=',')\n",
    "    labels = np.genfromtxt(f\"data_labels\\\\{row[1]['target_path']}\", delimiter=',')\n",
    "\n",
    "    # split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    c_test = X_test[:, -2:]\n",
    "\n",
    "    limits_ind = [20,120,20,120]\n",
    "    limits_indx = np.where((c_test[:,0] > limits_ind[0]) & (c_test[:,0] < limits_ind[1])\n",
    "                            & (c_test[:,1] > limits_ind[2]) & (c_test[:,1] < limits_ind[3]))[0]\n",
    "    \n",
    "    y_test = y_test[limits_indx]\n",
    "\n",
    "\n",
    "    X_train_split, dummy_x, y_train_split, dummy_y = train_test_split(X_train, y_train, test_size=0.6, random_state=42)\n",
    "    X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X_train_split, y_train_split, test_size=0.2, random_state=42)\n",
    "    \n",
    "\n",
    "    # SUPPORT VECTOR MACHINES\n",
    "    # load prediction from coord SVM\n",
    "    pred_svm_coord = np.genfromtxt(f\"testingSVM\\\\SVM_coord\\\\SVM_coord_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from no coord SVM\n",
    "    pred_svm_no_coord = np.genfromtxt(f\"testingSVM\\\\SVM\\\\SVM_id_{id_dataset}.csv\", delimiter=',')\n",
    "    \n",
    "    # load prediction from GSVM\n",
    "    pred_gsvm = np.genfromtxt(f\"testingSVM\\\\GSVM\\\\GSVM_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # load prediction from MSGSVM \n",
    "    pred_msgsvm = np.genfromtxt(f\"testingSVM\\\\MSGSVM\\\\MSGSVM_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # get single bandwidth\n",
    "    bandwidth = np.genfromtxt(f\"tuningSVM\\\\single_bandwidth\\\\single_bandwidth_id_{id_dataset}.csv\", delimiter=',')\n",
    "\n",
    "    # calculate rmse\n",
    "    rmse_svm_coord = mean_squared_error(y_test_global, pred_svm_coord, squared=False)\n",
    "    rmse_svm_no_coord = mean_squared_error(y_test_global, pred_svm_no_coord, squared=False)\n",
    "    rmse_gsvm = mean_squared_error(y_test, pred_gsvm, squared=False)\n",
    "    rmse_msgsvm = mean_squared_error(y_test, pred_msgsvm, squared=False)\n",
    "\n",
    "\n",
    "    # append to list\n",
    "    svm_coord_rmse.append(rmse_svm_coord)\n",
    "    svm_no_coord_rmse.append(rmse_svm_no_coord)\n",
    "    gsvm_rmse.append(rmse_gsvm)\n",
    "    msgsvm_rmse.append(rmse_msgsvm)\n",
    "    svm_bandwidth.append(bandwidth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-0707857bcc39>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataSVM['algorithm'] = ['SupportVectorMachines'] * len(result_data)\n",
      "<ipython-input-51-0707857bcc39>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataSVM['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
      "<ipython-input-51-0707857bcc39>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataSVM['bandwidth'] = svm_bandwidth\n",
      "<ipython-input-51-0707857bcc39>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_dataSVM['Coordinates'] = svm_coord_rmse\n"
     ]
    }
   ],
   "source": [
    "result_dataSVM = metadata[['relationship','trend', 'surface_level', 'spatial_autocorrelation', ]]\n",
    "result_dataSVM['algorithm'] = ['SupportVectorMachines'] * len(result_data)\n",
    "result_dataSVM['spatial_autocorrelation_val'] = spatial_autocorrelation_val\n",
    "result_dataSVM['bandwidth'] = svm_bandwidth\n",
    "\n",
    "\n",
    "result_dataSVM['Coordinates'] = svm_coord_rmse\n",
    "result_dataSVM['No_coordinates'] = svm_no_coord_rmse\n",
    "result_dataSVM['Add_coordinates_change'] = difference_percent(svm_no_coord_rmse, svm_coord_rmse)\n",
    "result_dataSVM['Geographical'] = gsvm_rmse\n",
    "result_dataSVM['Geographical_change'] = difference_percent(svm_no_coord_rmse, gsvm_rmse)\n",
    "result_dataSVM['Multiscale'] = msgsvm_rmse\n",
    "result_dataSVM['Multiscale_change'] = difference_percent(svm_no_coord_rmse, msgsvm_rmse)\n",
    "\n",
    "result_dataSVM.to_csv(\"resultSVM.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines',\n",
       " 'SupportVectorMachines']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['SupportVectorMachines'] * len(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
