{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class GeographicalModel:\n",
    "\n",
    "    def __init__(self,\n",
    "        algorithm: str, \n",
    "        parameters: dict,\n",
    "        bandwidth_type: str,\n",
    "        kernel: str,\n",
    "        kernel_param: list):\n",
    "\n",
    "        self.algorithm = algorithm\n",
    "        self.parameters = parameters\n",
    "        self.bandwidth_type = bandwidth_type\n",
    "        self.kernel = kernel\n",
    "        self.kernel_param = kernel_param\n",
    "\n",
    "    def kernel_gaussian(self, distances, b=1): \n",
    "\n",
    "        return np.exp(-0.5*(distances/b)**2)\n",
    "    \n",
    "    def kernel_none(self, distances):\n",
    "\n",
    "        return distances\n",
    "    \n",
    "    def interpolate_linear(self, coordinates, values, new_coordinates):\n",
    "         \n",
    "        # Create an empty array to store the interpolated values\n",
    "        interpolated_values = np.zeros(len(new_coordinates))\n",
    "\n",
    "        for i, new_coord in enumerate(new_coordinates):\n",
    "            # Get the new x and y coordinates\n",
    "            x_new, y_new = new_coord\n",
    "        \n",
    "            # Find the four closest points surrounding the new coordinates\n",
    "            distances = np.sqrt((coordinates[:, 0] - x_new)**2 + (coordinates[:, 1] - y_new)**2)\n",
    "            indices = np.argsort(distances)[:4]\n",
    "            closest_coords = coordinates[indices]\n",
    "            closest_values = values[indices]\n",
    "        \n",
    "            # Compute the weights based on inverse distance\n",
    "            weights = 1 / distances[indices]\n",
    "            weights /= weights.sum()\n",
    "        \n",
    "            # Interpolate the value for the new coordinates\n",
    "            interpolated_values[i] = np.dot(weights, closest_values)\n",
    "\n",
    "        return interpolated_values\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    def create_stepped_matrix(self, shape, step):\n",
    "\n",
    "        rows, cols = shape\n",
    "        # Initialize the matrix with zeros\n",
    "        matrix = np.zeros((rows, cols), dtype=int)\n",
    "\n",
    "        # Assign values to the matrix in steps\n",
    "        for r in range(0, rows, step):\n",
    "            for c in range(0, cols, step):\n",
    "\n",
    "                # Calculate the value based on the row and column indices\n",
    "                value = (r // step) * (cols // step) + (c // step)\n",
    "                # Assign the value to the current window\n",
    "                matrix[r:r+step, c:c+step] = value\n",
    "        return matrix    \n",
    "\n",
    "    def tune(\n",
    "        self,\n",
    "        coordinates_train,\n",
    "        features_train,\n",
    "        labels_train,\n",
    "        n_jobs: int,\n",
    "        bandwidths: list,\n",
    "        step=1,\n",
    "        limits=False,\n",
    "        limits_ind=[0,0,0,0]):\n",
    "\n",
    "        self.limits = limits\n",
    "        self.limits_ind = limits_ind\n",
    "\n",
    "        # add column containg order \n",
    "        coordinates_train = np.hstack((coordinates_train, np.arange(0, coordinates_train.shape[0], 1).reshape((-1,1))))\n",
    "\n",
    "        # split the data according to limits\n",
    "        if limits == True:\n",
    "\n",
    "            limits_indx = np.where((coordinates_train[:,0] > limits_ind[0]) & (coordinates_train[:,0] < limits_ind[1])\n",
    "                                    & (coordinates_train[:,1] > limits_ind[2]) & (coordinates_train[:,1] < limits_ind[3]))[0]\n",
    "            coordinates_train_limits = coordinates_train[limits_indx]\n",
    "        else:\n",
    "            coordinates_train_limits=coordinates_train\n",
    "\n",
    "        # create an instance of scikit-learn estimator\n",
    "        Model = eval(self.algorithm)(**self.parameters)\n",
    "\n",
    "        min_x, max_x = limits_ind[0], limits_ind[1]\n",
    "        min_y, max_y = limits_ind[2], limits_ind[3]\n",
    "\n",
    "        mask_matrix = self.create_stepped_matrix((max_x-min_x, max_y-min_y), step)\n",
    "\n",
    "        x_coord_linspace = np.arange(limits_ind[0], limits_ind[1], 1)\n",
    "        y_coord_linspace = np.arange(limits_ind[2], limits_ind[3], 1)\n",
    "\n",
    "        bandwidth_results = np.zeros((coordinates_train.shape[0], len(bandwidths)))\n",
    "\n",
    "        x_grid, y_grid = np.meshgrid(x_coord_linspace, y_coord_linspace)\n",
    "        \n",
    "        # --------CYCLE-----------------------\n",
    "        def delayed_function(region_id,\n",
    "                             bandwidth_value,\n",
    "                             kernel,\n",
    "                             kernel_param,\n",
    "                             coordinates_train,\n",
    "                             features_train, \n",
    "                             label_train\n",
    "                            \n",
    "        ):\n",
    "            \n",
    "            x_coord_centroid = x_grid[np.where(mask_matrix == region_id, True, False)].mean()\n",
    "            y_coord_centroid = y_grid[np.where(mask_matrix == region_id, True, False)].mean()\n",
    "\n",
    "            # calculate distance matrix for prediction samples\n",
    "            distance_matrix = np.sqrt((x_coord_centroid - coordinates_train[:, 0])**2 + (y_coord_centroid - coordinates_train[:, 1])**2)\n",
    "\n",
    "            # get indices for inner\n",
    "            inner_boolean_matrix = np.where(distance_matrix < step/2, True, False)\n",
    "\n",
    "            if inner_boolean_matrix.sum() > 0:\n",
    "\n",
    "                outer_boolean_matrix = np.where(distance_matrix < bandwidth_value, True, False) ^ inner_boolean_matrix\n",
    "\n",
    "                kernel_matrix =  getattr(self, f'kernel_{kernel}')(distance_matrix.flatten()[outer_boolean_matrix], *kernel_param)\n",
    "\n",
    "                Model.fit(features_train[outer_boolean_matrix], label_train[outer_boolean_matrix])\n",
    "                #Model.fit(features_train[outer_boolean_matrix], label_train[outer_boolean_matrix], kernel_matrix)\n",
    "                prediction = Model.predict(features_train[inner_boolean_matrix])\n",
    "\n",
    "                error = mean_squared_error(label_train[inner_boolean_matrix], prediction, squared=False)\n",
    "                error_matrix[inner_boolean_matrix] = error\n",
    "            \n",
    "            else:\n",
    "                error_matrix[inner_boolean_matrix] = -1\n",
    "\n",
    "            return error_matrix\n",
    "\n",
    "        for n_bandwidth, bandwidth_value in tqdm(enumerate(bandwidths), total=len(bandwidths), position=0):\n",
    "\n",
    "\n",
    "            path = tempfile.mkdtemp()\n",
    "            temp_path = os.path.join(path,'result_array.mmap')\n",
    "\n",
    "            error_matrix = np.memmap(temp_path, dtype=float, shape=(coordinates_train.shape[0]), mode='w+')\n",
    "\n",
    "            error_matrix = Parallel(n_jobs=n_jobs)(delayed(delayed_function) (\n",
    "                region_id, \n",
    "                bandwidth_value, \n",
    "                self.kernel, \n",
    "                self.kernel_param, \n",
    "                coordinates_train, \n",
    "                features_train, \n",
    "                labels_train) \n",
    "\n",
    "                for region_id in (np.unique(mask_matrix)))\n",
    "            \n",
    "            bandwidth_results[:, n_bandwidth] = error_matrix[0]\n",
    "            \n",
    "            try:\n",
    "                shutil.rmtree(path)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "\n",
    "        single_bandwidth_error = np.mean(bandwidth_results, axis=0)\n",
    "        single_best_bandwidth = bandwidths[np.argmin(single_bandwidth_error)]\n",
    "\n",
    "        best_bw_ind = (np.argmin(bandwidth_results, axis=1))\n",
    "        best_bw = np.array(list(map(lambda x: bandwidths[x] , best_bw_ind)))\n",
    "\n",
    "        self.best_bw = best_bw\n",
    "        self.single_best_bandwidth = single_best_bandwidth\n",
    "\n",
    "        return single_best_bandwidth, best_bw\n",
    "\n",
    "    def predict(self,\n",
    "                bandwidth,\n",
    "                bandwidth_type,\n",
    "                interpolation,\n",
    "                coordinates_train,\n",
    "                features_train,\n",
    "                labels_train,\n",
    "                coordinates_test,\n",
    "                features_test,\n",
    "                n_jobs):\n",
    "        \n",
    "\n",
    "        coordinates_test = np.hstack((coordinates_test, np.arange(0, coordinates_test.shape[0], 1).reshape((-1,1))))\n",
    "\n",
    "        if isinstance(bandwidth, int):\n",
    "            bandwidth_values = np.full(shape=(coordinates_test.shape[0]), fill_value=bandwidth)\n",
    "        else:\n",
    "            interpolation_str = f'interpolate_{interpolation}'\n",
    "            bandwidth_values = getattr(self, interpolation_str)(coordinates_train, bandwidth, coordinates_test[:, :2])\n",
    "\n",
    "        Model = eval(self.algorithm)(**self.parameters)\n",
    "\n",
    "        path = tempfile.mkdtemp()\n",
    "        temp_path = os.path.join(path,'prediction_array.mmap')\n",
    "\n",
    "        prediction_matrix = np.memmap(temp_path, dtype=float, shape=(coordinates_test.shape[0]), mode='w+')\n",
    "\n",
    "        def delayed_function(location, \n",
    "                             bandwidth_values,  \n",
    "                             coordinates_train, \n",
    "                             features_train, \n",
    "                             labels_train,\n",
    "                             features_test\n",
    "                             ):\n",
    "            \n",
    "\n",
    "            order_n = location[2]\n",
    "\n",
    "            distance_matrix = np.sqrt(((location[0] - coordinates_train[:, 0])**2 + (location[1] - coordinates_train[:, 1])**2))\n",
    "\n",
    "            if self.bandwidth_type == 'fixed':\n",
    "\n",
    "                boolean_matrix = np.where(distance_matrix <= bandwidth_values[int(order_n)], True, False).flatten()\n",
    "                \n",
    "            elif self.bandwidth_type == 'adaptive':\n",
    "                    \n",
    "                boolean_matrix = np.full(shape=distance_matrix.shape, fill_value=False)\n",
    "                n_closest_ind =  np.argsort(distance_matrix)[:bandwidth_values+1]\n",
    "                boolean_matrix[n_closest_ind] = True\n",
    "\n",
    "            boolean_matrix[int(order_n)] = False\n",
    "\n",
    "            weight_matrix = np.zeros((distance_matrix.shape))\n",
    "            kernel_matrix =  getattr(self, f'kernel_{self.kernel}')(distance_matrix.flatten()[boolean_matrix], *self.kernel_param)\n",
    "            weight_matrix[boolean_matrix] = kernel_matrix\n",
    "            \n",
    "            #Model.fit(features_train[boolean_matrix], labels_train[boolean_matrix], kernel_matrix)\n",
    "            Model.fit(features_train[boolean_matrix], labels_train[boolean_matrix])\n",
    "            prediction = Model.predict(features_test[int(order_n), :].reshape(1, -1))\n",
    "            prediction_matrix[int(order_n)] = prediction\n",
    "\n",
    "            return prediction_matrix\n",
    "        \n",
    "\n",
    "        prediction_matrix = Parallel(n_jobs=n_jobs)(delayed(delayed_function) (\n",
    "                location, \n",
    "                bandwidth_values,   \n",
    "                coordinates_train, \n",
    "                features_train, \n",
    "                labels_train,\n",
    "                features_test)\n",
    "\n",
    "            for location in coordinates_test)\n",
    "        \n",
    "        prediction_arr = np.array(prediction_matrix[0].tolist())\n",
    "\n",
    "        try:\n",
    "            shutil.rmtree(path)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        return prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
